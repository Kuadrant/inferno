version: '3'

services:
  inferno_envoy:
    image: istio/proxyv2:1.15.0
    container_name: inferno_envoy
    entrypoint: /entrypoint.sh
    command: [
      "--log-level", "${ENVOY_LOG_LEVEL:-info}",
      "--service-cluster", "envoy-front",
      "--service-node", "envoy-front"
    ]
    environment:
      OPENAI_API_HOST: "${OPENAI_API_HOST:-api.openai.com}"
      KSERVE_API_HOST: "${KSERVE_API_HOST:-192.168.97.4}"
      KSERVE_API_HOST_HEADER: "${KSERVE_API_HOST_HEADER:-huggingface-llm-default.example.com}"
    ports:
      - 10000:10000
      - 15000:15000
    networks:
      - inferno-network
    volumes:
      - ./envoy/entrypoint.sh:/entrypoint.sh

  inferno_ext_proc:
    container_name: inferno_ext_proc
    build:
      context: ./
    environment:
      # ExtProc Port
      EXT_PROC_PORT: "${EXT_PROC_PORT:-50051}"
      
      # Semantic Cache Settings
      EMBEDDING_MODEL_SERVER: "${EMBEDDING_MODEL_SERVER:-http://127.0.0.1/v1/models/embedding-model:predict}"
      EMBEDDING_MODEL_HOST: "${EMBEDDING_MODEL_HOST:-embedding-model-default.example.com}"
      SIMILARITY_THRESHOLD: "${SIMILARITY_THRESHOLD:-0.75}"
      
      # Prompt Guard Settings
      GUARDIAN_API_KEY: "${GUARDIAN_API_KEY:-test}"
      GUARDIAN_URL: "${GUARDIAN_URL:-http://example.com}"
      DISABLE_PROMPT_RISK_CHECK: "${DISABLE_PROMPT_RISK_CHECK:-no}"
      DISABLE_RESPONSE_RISK_CHECK: "${DISABLE_RESPONSE_RISK_CHECK:-no}"
    expose:
      - 50051
    networks:
      - inferno-network

networks:
  inferno-network:
    driver: bridge